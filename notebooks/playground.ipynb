{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from numba import njit\n",
    "\n",
    "import bayesflow as bf\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../assets/\")\n",
    "from priors import sample_gamma, sample_eta, sample_random_walk\n",
    "from likelihood import sample_non_stationary_diffusion_process, _sample_diffusion_trial\n",
    "from context import generate_context\n",
    "from configurations import approximator_settings    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NETWORK = True\n",
    "FIT_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OBS = 246\n",
    "RT_UPPER_BOUND = 6.0\n",
    "RT_LOWER_BOUND = 0.2\n",
    "NUM_SAMPLES = 2000\n",
    "NUM_RESIMULATIONS = 500\n",
    "\n",
    "LOCAL_PARAM_LABELS = [\n",
    "    'Sensitivity', 'Threshold', 'Non-decision time',\n",
    "]\n",
    "LOCAL_PARAM_NAMES  = [\n",
    "    r'b_v', r'a', r'\\tau_1'\n",
    "]\n",
    "\n",
    "FONT_SIZE_1 = 20\n",
    "FONT_SIZE_2 = 18\n",
    "FONT_SIZE_3 = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplar parameter trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = sample_eta()\n",
    "theta_t = sample_random_walk(eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(theta_t.shape[0])\n",
    "fig, axarr = plt.subplots(1, 3, figsize=(18, 4))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    if i == 7:\n",
    "        break\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.plot(\n",
    "        time,\n",
    "        theta_t[:, i],\n",
    "        color='maroon'\n",
    "    )\n",
    "    ax.set_title(f'{LOCAL_PARAM_LABELS[i]} (${LOCAL_PARAM_NAMES[i]}$)', fontsize=FONT_SIZE_1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    if i == 0 or i == 4:\n",
    "        ax.set_ylabel(\"Parameter value\", fontsize=FONT_SIZE_2)\n",
    "    if i > 3:\n",
    "        ax.set_xlabel(\"Time\", fontsize=FONT_SIZE_2)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = bf.simulation.TwoLevelPrior(\n",
    "    hyper_prior_fun=sample_eta,\n",
    "    local_prior_fun=sample_random_walk,\n",
    "    shared_prior_fun=sample_gamma\n",
    "    )\n",
    "\n",
    "context = bf.simulation.ContextGenerator(\n",
    "    batchable_context_fun=generate_context,\n",
    "    )\n",
    "\n",
    "likelihood = bf.simulation.Simulator(\n",
    "    simulator_fun=sample_non_stationary_diffusion_process,\n",
    "    context_generator=context,\n",
    "    )\n",
    "\n",
    "model = bf.simulation.TwoLevelGenerativeModel(\n",
    "    prior=prior,\n",
    "    simulator=likelihood,\n",
    "    name=\"random_walk_diffusion_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = model(1)\n",
    "sns.histplot(sim_data['sim_data'][0, :, 0], color='maroon')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 50000\n",
    "# prior_samples = prior(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER_PRIOR_MEAN = np.round(prior_samples['hyper_parameters'].mean(axis=0), 2)\n",
    "# HYPER_PRIOR_STD = np.round(prior_samples['hyper_parameters'].std(axis=0), 2)\n",
    "\n",
    "# local_samples = prior_samples['local_parameters'].reshape(-1, prior_samples['local_parameters'].shape[-1])\n",
    "# LOCAL_PRIOR_MEAN = np.round(local_samples.mean(axis=0), 2)\n",
    "# LOCAL_PRIOR_STD = np.round(local_samples.std(axis=0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_input(raw_dict):\n",
    "    # prepare data\n",
    "    data = raw_dict.get(\"sim_data\")\n",
    "    truth_context = np.array(raw_dict.get(\"sim_batchable_context\"))[:, :, 0][:, :, None]\n",
    "    face_context = np.array(raw_dict.get(\"sim_batchable_context\"))[:, :, 1][:, :, None]\n",
    "    validity_context = np.array(raw_dict.get(\"sim_batchable_context\"))[:, :, 2][:, :, None]\n",
    "    summary_conditions = np.c_[data, truth_context, to_categorical(face_context), validity_context]\n",
    "\n",
    "    theta_t = raw_dict.get(\"local_prior_draws\")\n",
    "    eta = raw_dict.get(\"hyper_prior_draws\")\n",
    "    gamma = raw_dict.get(\"shared_prior_draws\")\n",
    "\n",
    "    # out_dict = dict(\n",
    "    #     local_parameters=((theta_t - LOCAL_PRIOR_MEAN) / LOCAL_PRIOR_STD).astype(np.float32),\n",
    "    #     hyper_parameters=((eta - HYPER_PRIOR_MEAN) / HYPER_PRIOR_STD).astype(np.float32),\n",
    "    #     summary_conditions=summary_conditions.astype(np.float32),\n",
    "    # )\n",
    "    out_dict = dict(\n",
    "        local_parameters=theta_t.astype(np.float32),\n",
    "        hyper_parameters=eta.astype(np.float32),\n",
    "        shared_parameters=gamma.astype(np.float32),\n",
    "        summary_conditions=summary_conditions.astype(np.float32),\n",
    "    )\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_network = bf.networks.HierarchicalNetwork(\n",
    "    [\n",
    "        Sequential(\n",
    "            [\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm1_hidden_units\"], return_sequences=True)),\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm2_hidden_units\"], return_sequences=True)),\n",
    "            ]\n",
    "        ),\n",
    "        Sequential(\n",
    "            [\n",
    "                Bidirectional(LSTM(approximator_settings[\"lstm3_hidden_units\"]))\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_network = bf.amortizers.AmortizedPosterior(\n",
    "    bf.networks.InvertibleNetwork(\n",
    "        num_params=3,\n",
    "        **approximator_settings.get(\"local_amortizer_settings\")\n",
    "    )\n",
    ")\n",
    "\n",
    "global_network = bf.amortizers.AmortizedPosterior(\n",
    "    bf.networks.InvertibleNetwork(\n",
    "        num_params=3+3,\n",
    "        **approximator_settings.get(\"global_amortizer_settings\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amortizer = bf.amortizers.TwoLevelAmortizedPosterior(\n",
    "    local_amortizer=local_network,\n",
    "    global_amortizer=global_network,\n",
    "    summary_net=summary_network\n",
    ")\n",
    "\n",
    "trainer = bf.trainers.Trainer(\n",
    "    amortizer=amortizer,\n",
    "    generative_model=model,\n",
    "    configurator=configure_input,\n",
    "    **approximator_settings.get(\"trainer\"),\n",
    "    checkpoint_path=\"../checkpoints/model_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_NETWORK:\n",
    "    history = trainer.train_online(\n",
    "        epochs=100,\n",
    "        iterations_per_epoch=1000,\n",
    "        batch_size=32\n",
    "    )\n",
    "    loss_plot = bf.diagnostics.plot_losses(trainer.loss_history.get_plottable())\n",
    "else:\n",
    "    loss_plot = bf.diagnostics.plot_losses(trainer.loss_history.get_plottable())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit to Empirical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('../data_super.xlsx')\n",
    "data_witness = data.loc[(data.condition == \"Kongruenz Witness\") | (data.condition == \"Inkongruenz Witness\")]\n",
    "subject_id = data_witness.subject_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIT_MODEL:\n",
    "    local_post_samples_z = np.full((len(subject_id), NUM_OBS, NUM_SAMPLES, 7), np.nan)\n",
    "    global_post_samples_z = np.full((len(subject_id), NUM_SAMPLES, 5), np.nan)\n",
    "\n",
    "    resim_data = np.full((len(subject_id), NUM_RESIMULATIONS, NUM_OBS, 7), np.nan)\n",
    "\n",
    "    for i, id in enumerate(subject_id):\n",
    "        # model fitting\n",
    "        person_data = data_witness.loc[data_witness.subject_id == id]\n",
    "        person_data.loc[:, \"correctResponse\"] = np.where(person_data[\"correctResponse\"] == \"Lüge\", 0, 1)\n",
    "\n",
    "        truth_context = person_data.correctResponse\n",
    "        face_context = person_data.Anzahl_Gesichter - 1\n",
    "        validity_context = person_data.ValiditätenInv - 0.5\n",
    "\n",
    "        resp = person_data.Antwort\n",
    "        rt = person_data.duration / 1000\n",
    "        rt.loc[rt > RT_UPPER_BOUND] = np.nan\n",
    "        rt.loc[rt < RT_LOWER_BOUND] = np.nan\n",
    "        mask = np.isfinite(rt)\n",
    "\n",
    "        data_configured = np.c_[\n",
    "            rt[mask], resp[mask], truth_context[mask],\n",
    "            to_categorical(face_context[mask]), validity_context[mask]\n",
    "        ][None, :, :].astype(np.float32)\n",
    "\n",
    "        post_samples = amortizer.sample({'summary_conditions': data_configured}, n_samples=NUM_SAMPLES)\n",
    "        local_post_samples_z[i, mask] = post_samples['local_samples']\n",
    "        global_post_samples_z[i] = post_samples['global_samples']\n",
    "\n",
    "        # posterior resimulation\n",
    "        idx = np.random.choice(np.arange(NUM_SAMPLES), NUM_RESIMULATIONS, replace=False)\n",
    "        local_post_samples = post_samples['local_samples'][:, idx] * LOCAL_PRIOR_STD + LOCAL_PRIOR_MEAN\n",
    "        context = np.c_[truth_context[mask], face_context[mask], validity_context[mask]].astype(np.float32)\n",
    "        sub_id = np.full((NUM_RESIMULATIONS, NUM_OBS), id)\n",
    "        sim_seq = np.repeat(np.arange(NUM_RESIMULATIONS), NUM_OBS).reshape((NUM_RESIMULATIONS, NUM_OBS))\n",
    "        for j in range(NUM_RESIMULATIONS):\n",
    "            x = sample_non_stationary_diffusion_process(local_post_samples[:, j].astype(np.float32), context)\n",
    "            resim_data[i, j, mask, 2:] = np.c_[x, context]\n",
    "        resim_data[i, :, :, 0] = sub_id\n",
    "        resim_data[i, :, :, 1] = sim_seq\n",
    "\n",
    "    np.save(\"../data/local_post_samples_z.npy\", local_post_samples_z)\n",
    "    np.save(\"../data/global_post_samples_z.npy\", global_post_samples_z)\n",
    "    np.save(\"../data/post_resim_data.npy\", resim_data)\n",
    "else:\n",
    "    local_post_samples_z = np.load(\"../data/local_post_samples_z.npy\")\n",
    "    global_post_samples_z = np.load(\"../data/global_post_samples_z.npy\")\n",
    "    post_resim_data = np.load(\"../data/post_resim_data.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_post = local_post_samples_z * LOCAL_PRIOR_STD + LOCAL_PRIOR_MEAN\n",
    "local_post_median_congruent = np.nanmedian(local_post[:42], axis=2)\n",
    "local_post_mean_congruent = np.nanmean(local_post_median_congruent, axis=0)\n",
    "local_post_ci_congruent = np.nanquantile(local_post_median_congruent, [0.05, 0.95], axis=0)\n",
    "\n",
    "local_post_median_incongruent = np.nanmedian(local_post[42:], axis=2)\n",
    "local_post_mean_incongruent = np.nanmean(local_post_median_incongruent, axis=0)\n",
    "local_post_ci_incongruent = np.nanquantile(local_post_median_incongruent, [0.05, 0.95], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(local_post_mean_congruent.shape[0])\n",
    "fig, axarr = plt.subplots(2, 4, figsize=(18, 6))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    if i == 7:\n",
    "        break\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.plot(\n",
    "        time,\n",
    "        local_post_mean_congruent[:, i],\n",
    "        color='maroon', alpha=0.5, linewidth=3\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        time,\n",
    "        local_post_ci_congruent[0, :, i],\n",
    "        local_post_ci_congruent[1, :, i],\n",
    "        color='maroon', alpha=0.2, linewidth=0\n",
    "    )\n",
    "    ax.plot(\n",
    "        time,\n",
    "        local_post_mean_incongruent[:, i],\n",
    "        color='midnightblue', alpha=0.5, linewidth=3\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        time,\n",
    "        local_post_ci_incongruent[0, :, i],\n",
    "        local_post_ci_incongruent[1, :, i],\n",
    "        color='midnightblue', alpha=0.2, linewidth=0\n",
    "    )\n",
    "    ax.set_title(f'{LOCAL_PARAM_LABELS[i]} (${LOCAL_PARAM_NAMES[i]}$)', fontsize=FONT_SIZE_1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    if i == 0 or i == 4:\n",
    "        ax.set_ylabel(\"Parameter value\", fontsize=FONT_SIZE_2)\n",
    "    if i > 3:\n",
    "        ax.set_xlabel(\"Time\", fontsize=FONT_SIZE_2)\n",
    "\n",
    "handles = [\n",
    "    Line2D(\n",
    "        xdata=[], ydata=[], markersize=10, lw=3,\n",
    "        color='maroon', label='Average posterior median (congruent)'\n",
    "    ),\n",
    "    Line2D(\n",
    "        xdata=[], ydata=[], markersize=10, lw=3,\n",
    "        color='midnightblue', label='Average posterior median (incongruent)'\n",
    "    ),\n",
    "    Patch(\n",
    "        color='maroon', label='Average posterior median (congruent)', alpha=0.4\n",
    "    ),\n",
    "    Patch(\n",
    "        color='midnightblue', label='Average posterior median (incongruent)', alpha=0.4\n",
    "    )\n",
    "]\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "fig.legend(\n",
    "    handles,\n",
    "    ['Average posterior median (congruent)', 'Average posterior median (incongruent)',\n",
    "    '90%-CI (congruent)', '90%-CI (incongruent)'],\n",
    "    fontsize=FONT_SIZE_2, bbox_to_anchor=(0.5, -0.05),\n",
    "    loc=\"center\", ncol=2\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../plots/average_param_trajectory.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Re-simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = data_witness.loc[:, (\"condition\", \"subject_id\", \"Antwort\", \"correct\", \"correctResponse\", \"Anzahl_Gesichter\", \"ValiditätenInv\", \"duration\")]\n",
    "emp_df = emp_df.rename(\n",
    "    columns={\n",
    "        \"subject_id\": \"id\", \"Antwort\": \"resp\", \"correctResponse\": \"truth_context\",\n",
    "        \"Anzahl_Gesichter\": \"face_context\", \"ValiditätenInv\": \"validity_context\", \"duration\": \"rt\"})\n",
    "\n",
    "emp_df.loc[:, \"rt\"] = emp_df.rt / 1000\n",
    "emp_df.loc[emp_df[\"rt\"] > 6.0, \"rt\"] = np.nan\n",
    "emp_df.loc[emp_df[\"rt\"] < 0.2, \"rt\"] = np.nan\n",
    "emp_df['correct'] = emp_df['correct'].astype(str)\n",
    "emp_df.loc[:, \"correct\"] = np.where(emp_df[\"correct\"] == \"True\", 1, 0)\n",
    "\n",
    "emp_df.loc[:, \"condition\"] = np.where(emp_df[\"condition\"] == \"Kongruenz Witness\", 1, 0)\n",
    "emp_df.loc[:, \"truth_context\"] = np.where(emp_df[\"truth_context\"] == \"Lüge\", 0, 1)\n",
    "emp_df.loc[:, \"face_context\"] = emp_df.face_context - 1\n",
    "emp_df.loc[:, \"validity_context\"] = emp_df.validity_context - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_data = resim_data.reshape(-1, 7)\n",
    "resim_df = pd.DataFrame(reshaped_data, columns=['id', 'sim', 'rt', 'resp', 'truth_context', 'face_context', 'validity_context'])\n",
    "resim_df[\"condition\"] = np.where(resim_df[\"id\"] < 43, 1, 0)\n",
    "resim_df[\"correct\"] = np.where(resim_df[\"resp\"] == resim_df[\"truth_context\"], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_data = resim_df.groupby(['condition', 'validity_context'])\n",
    "# resim_summaries = grouped_data.agg({\n",
    "#             'rt': ['median', \"std\"],\n",
    "#             'correct': ['mean', \"std\"]\n",
    "#         }).reset_index(drop=False)\n",
    "# resim_summaries.columns = [\"condition\", \"validity_context\", 'rt_median', 'rt_std', 'acc', 'acc_std']\n",
    "\n",
    "grouped_data = resim_df.groupby(['id', 'condition', 'validity_context'])\n",
    "resim_summaries = grouped_data.agg({\n",
    "            'rt': ['median'],\n",
    "            'correct': ['mean']\n",
    "        }).reset_index(drop=False)\n",
    "resim_summaries.columns = ['id', \"condition\", \"validity_context\", 'rt_median', 'acc']\n",
    "\n",
    "grouped_data = resim_summaries.groupby(['condition', 'validity_context'])\n",
    "resim_summaries = grouped_data.agg({\n",
    "            'rt_median': ['mean', 'std'],\n",
    "            'acc': ['mean', 'std']\n",
    "        }).reset_index(drop=False)\n",
    "resim_summaries.columns = [\"condition\", \"validity_context\", 'avg_rt_median', 'std_rt_median', 'avg_acc', 'std_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_data = emp_df.groupby(['condition', 'validity_context'])\n",
    "# empiric_summaries = grouped_data.agg({\n",
    "#             'rt': ['median', \"std\"],\n",
    "#             'correct': ['mean', \"std\"]\n",
    "#         }).reset_index(drop=False)\n",
    "# empiric_summaries.columns = [\"condition\", \"validity_context\", 'rt_median', 'rt_std', 'acc', 'acc_std']\n",
    "# empiric_summaries\n",
    "\n",
    "grouped_data = emp_df.groupby(['id', 'condition', 'validity_context'])\n",
    "empiric_summaries = grouped_data.agg({\n",
    "            'rt': ['median'],\n",
    "            'correct': ['mean']\n",
    "        }).reset_index(drop=False)\n",
    "empiric_summaries.columns = ['id', \"condition\", \"validity_context\", 'rt_median', 'acc']\n",
    "\n",
    "grouped_data = empiric_summaries.groupby(['condition', 'validity_context'])\n",
    "empiric_summaries = grouped_data.agg({\n",
    "            'rt_median': ['mean', 'std'],\n",
    "            'acc': ['mean', 'std']\n",
    "        }).reset_index(drop=False)\n",
    "empiric_summaries.columns = [\"condition\", \"validity_context\", 'avg_rt_median', 'std_rt_median', 'avg_acc', 'std_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [empiric_summaries, resim_summaries]\n",
    "\n",
    "ESCAPE = [-0.2, 0.2]\n",
    "X_AXIS_VALUES = np.arange(8) * 1.5\n",
    "COLOR = ['black', 'maroon']\n",
    "CONDITION_NAMES = ['Incongruent', 'Congruent']\n",
    "LABELS = [\"Empiric\", \"Re-simulated\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    for j in range(2):\n",
    "        ax.scatter(\n",
    "            X_AXIS_VALUES + ESCAPE[j],\n",
    "            summaries[j].loc[summaries[j].condition == i, 'avg_rt_median'],\n",
    "            color=COLOR[j], label=LABELS[j]\n",
    "        )\n",
    "        ax.errorbar(\n",
    "            X_AXIS_VALUES + ESCAPE[j],\n",
    "            summaries[j].loc[summaries[j].condition == i, 'avg_rt_median'],\n",
    "            yerr= summaries[j].loc[summaries[j].condition == i, 'std_rt_median'],\n",
    "            fmt='o', color=COLOR[j], markersize=6, elinewidth=1.5, capsize=0\n",
    "        )\n",
    "    ax.set_xticks(X_AXIS_VALUES, empiric_summaries['validity_context'].unique().round(decimals=2))\n",
    "    ax.set_xlabel(\"Validity\", labelpad=15, fontsize=FONT_SIZE_2)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Response time median (s)\", labelpad=15, fontsize=FONT_SIZE_2)\n",
    "        fig.legend(\n",
    "            fontsize=FONT_SIZE_2, bbox_to_anchor=(0.5, -0.05),\n",
    "            loc=\"center\", ncol=5\n",
    "        )\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    ax.set_title(CONDITION_NAMES[i], pad=15, fontsize=FONT_SIZE_1)\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "sns.despine()\n",
    "fig.savefig(\"../plots/post_resim_rt.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    for j in range(2):\n",
    "        ax.scatter(\n",
    "            X_AXIS_VALUES + ESCAPE[j],\n",
    "            summaries[j].loc[summaries[j].condition == i, 'avg_acc'],\n",
    "            color=COLOR[j], label=LABELS[j]\n",
    "        )\n",
    "        ax.errorbar(\n",
    "            X_AXIS_VALUES + ESCAPE[j],\n",
    "            summaries[j].loc[summaries[j].condition == i, 'avg_acc'],\n",
    "            yerr= summaries[j].loc[summaries[j].condition == i, 'std_acc'],\n",
    "            fmt='o', color=COLOR[j], markersize=6, elinewidth=1.5, capsize=0\n",
    "        )\n",
    "        ax.axhline(y=0.5, color='black', linestyle='--', alpha=0.3)\n",
    "    ax.set_xticks(X_AXIS_VALUES, empiric_summaries['validity_context'].unique().round(decimals=2))\n",
    "    ax.set_xlabel(\"Validity\", labelpad=15, fontsize=FONT_SIZE_2)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Accuracy\", labelpad=15, fontsize=FONT_SIZE_2)\n",
    "        fig.legend(\n",
    "            fontsize=FONT_SIZE_2, bbox_to_anchor=(0.5, -0.05),\n",
    "            loc=\"center\", ncol=5\n",
    "        )\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    ax.set_title(CONDITION_NAMES[i], pad=15, fontsize=FONT_SIZE_1)\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "sns.despine()\n",
    "fig.savefig(\"../plots/post_resim_accuracy.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axarr = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "# for i, ax in enumerate(axarr.flat):\n",
    "#     for j in range(2):\n",
    "#         ax.scatter(\n",
    "#             X_AXIS_VALUES + ESCAPE[j],\n",
    "#             summaries[j].loc[summaries[j].condition == i, 'rt_median'],\n",
    "#             color=COLOR[j], label=LABELS[j]\n",
    "#         )\n",
    "#         ax.errorbar(\n",
    "#             X_AXIS_VALUES + ESCAPE[j],\n",
    "#             summaries[j].loc[summaries[j].condition == i, 'rt_median'],\n",
    "#             yerr= summaries[j].loc[summaries[j].condition == i, 'rt_std'],\n",
    "#             fmt='o', color=COLOR[j], markersize=6, elinewidth=1.5, capsize=0\n",
    "#         )\n",
    "#     ax.set_xticks(X_AXIS_VALUES, empiric_summaries['validity_context'].unique().round(decimals=2))\n",
    "#     ax.set_xlabel(\"Validity\", labelpad=15, fontsize=FONT_SIZE_2)\n",
    "#     if i == 0:\n",
    "#         ax.set_ylabel(\"Response time median (s)\", labelpad=15, fontsize=FONT_SIZE_2)\n",
    "#         fig.legend(\n",
    "#             fontsize=FONT_SIZE_2, bbox_to_anchor=(0.5, -0.05),\n",
    "#             loc=\"center\", ncol=5\n",
    "#         )\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "#     ax.set_title(CONDITION_NAMES[i], pad=15, fontsize=FONT_SIZE_1)\n",
    "# fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# fig.tight_layout()\n",
    "# sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
